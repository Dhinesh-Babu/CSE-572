{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import target.npy and train.npy\n",
    "# Train a model using train.npy\n",
    "# Test the model using target.npy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import the data\n",
    "train = np.load('dataset/train.npy')\n",
    "target = np.load('dataset/target.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Support Vector Machine </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.metrics import make_scorer\n",
    "# import numpy as np\n",
    "\n",
    "# # Create an instance of Support Vector Machine (SVM) Regression\n",
    "# svm_model = SVR(kernel='linear', cache_size=2000)  # You can change the kernel type as needed\n",
    "\n",
    "# # Define the number of folds for cross-validation\n",
    "# n_splits = 5\n",
    "\n",
    "# # Define the scoring function\n",
    "# scoring = make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)), greater_is_better=False)\n",
    "\n",
    "# # Perform cross-validation for SVM and calculate the RMSE for each fold\n",
    "# rmse_scores_svm = -cross_val_score(svm_model, train, target, cv=n_splits, scoring=scoring)\n",
    "\n",
    "# # Print the RMSE for each fold for SVM\n",
    "# for i, rmse_svm in enumerate(rmse_scores_svm, start=1):\n",
    "#     print(f\"SVM RMSE for fold {i}: {rmse_svm}\")\n",
    "\n",
    "# # Calculate the average RMSE across all folds for SVM\n",
    "# average_rmse_svm = np.mean(rmse_scores_svm)\n",
    "\n",
    "# # Print the average RMSE for SVM\n",
    "# print(\"Average SVM RMSE:\", average_rmse_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Initialize an empty list to store the root mean squared errors (RMSE) for each fold\n",
    "rmse_scores_svm = []\n",
    "\n",
    "# Perform cross-validation for SVM\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "    X_train = scaling.transform(X_train)\n",
    "    X_test = scaling.transform(X_test)\n",
    "    # Create an instance of Support Vector Machine (SVM) Regression\n",
    "    svm_model = SVR(kernel='linear',cache_size=7000)  # You can change the kernel type as needed\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the RMSE for the current fold for SVM\n",
    "    rmse_svm = np.sqrt(mean_squared_error(y_test, y_pred_svm))\n",
    "    \n",
    "    # Print the RMSE for the current fold for SVM\n",
    "    print(\"SVM RMSE:\", rmse_svm)\n",
    "    \n",
    "    # Append the RMSE to the list of scores for SVM\n",
    "    rmse_scores_svm.append(rmse_svm)\n",
    "\n",
    "# Calculate the average RMSE across all folds for SVM\n",
    "average_rmse_svm = np.mean(rmse_scores_svm)\n",
    "\n",
    "# Print the average RMSE for SVM\n",
    "print(\"Average SVM RMSE:\", average_rmse_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN RMSE: 1.8216407\n",
      "KNN RMSE: 1.806594\n",
      "KNN RMSE: 1.8060709\n",
      "KNN RMSE: 1.8160338\n",
      "KNN RMSE: 1.7953608\n",
      "Average KNN RMSE: 1.80914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Initialize an empty list to store the root mean squared errors (RMSE) for each fold\n",
    "rmse_scores_knn = []\n",
    "\n",
    "# Perform cross-validation for k-Nearest Neighbors (KNN)\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of k-Nearest Neighbors (KNN) Regressor\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=5)  # You can change the number of neighbors as needed\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    y_pred_knn = knn_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the RMSE for the current fold for KNN\n",
    "    rmse_knn = np.sqrt(mean_squared_error(y_test, y_pred_knn))\n",
    "    \n",
    "    # Print the RMSE for the current fold for KNN\n",
    "    print(\"KNN RMSE:\", rmse_knn)\n",
    "    \n",
    "    # Append the RMSE to the list of scores for KNN\n",
    "    rmse_scores_knn.append(rmse_knn)\n",
    "\n",
    "# Calculate the average RMSE across all folds for KNN\n",
    "average_rmse_knn = np.mean(rmse_scores_knn)\n",
    "\n",
    "# Print the average RMSE for KNN\n",
    "print(\"Average KNN RMSE:\", average_rmse_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.9063245190622926\n",
      "RMSE: 1.8114579320050195\n",
      "RMSE: 1.8569848179942037\n",
      "RMSE: 1.8469065603446555\n",
      "RMSE: 1.8518672416355282\n",
      "Average RMSE: 1.85470821420834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Initialize an empty list to store the root mean squared errors (RMSE) for each fold\n",
    "rmse_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of LinearRegression\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the RMSE for the current fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Print the RMSE for the current fold\n",
    "    print(\"RMSE:\", rmse)\n",
    "    \n",
    "    # Append the RMSE to the list of scores\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "average_rmse = np.mean(rmse_scores)\n",
    "\n",
    "# Print the average RMSE\n",
    "print(\"Average RMSE:\", average_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost with KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4121623\n",
      "RMSE: 1.3773588\n",
      "RMSE: 1.4391705\n",
      "RMSE: 1.4573854\n",
      "RMSE: 1.3527637\n",
      "Average RMSE: 1.4077681\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_scores_xgboost = []\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of xgb.DMatrix for the training and testing sets\n",
    "    xgb_train = xgb.DMatrix(X_train, y_train)\n",
    "    xgb_test = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "    # Define the parameters for the XGBoost model\n",
    "    params = {\n",
    "        'colsample_bytree': 0.8,                 \n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'objective': 'reg:squarederror',\n",
    "    }\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model = xgb.train(params, xgb_train, num_boost_round=100)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(xgb_test)\n",
    "\n",
    "    # Calculate the RMSE for the current fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Print the RMSE for the current fold\n",
    "    print(\"RMSE:\", rmse)\n",
    "\n",
    "    # Append the RMSE to the list of scores\n",
    "    rmse_scores_xgboost.append(rmse)\n",
    "\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "average_rmse = np.mean(rmse_scores_xgboost)\n",
    "\n",
    "# Print the average RMSE\n",
    "print(\"Average RMSE:\", average_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM with KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_scores_lightgbm = []\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of lgb.Dataset for the training and testing sets\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_test = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "    # Define the parameters for the LightGBM model\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    model = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the RMSE for the current fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Print the RMSE for the current fold\n",
    "    print(\"RMSE:\", rmse)\n",
    "\n",
    "    # Append the RMSE to the list of scores\n",
    "    rmse_scores_lightgbm.append(rmse)\n",
    "\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "average_rmse = np.mean(rmse_scores_lightgbm)\n",
    "\n",
    "# Print the average RMSE\n",
    "print(\"Average RMSE:\", average_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression with k fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Initialize an empty list to store the RMSE for each fold\n",
    "ridge_rmse_scores = []\n",
    "\n",
    "# Specify the regularization strength for Ridge regression\n",
    "alpha_ridge = 1.0\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of Ridge regression\n",
    "    ridge_model = Ridge(alpha=alpha_ridge)\n",
    "    \n",
    "    # Fit the model\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = ridge_model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE and append to the list\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Ridge RMSE:\", rmse)\n",
    "    ridge_rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE\n",
    "average_ridge_rmse = np.mean(ridge_rmse_scores)\n",
    "print(\"Average Ridge RMSE:\", average_ridge_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression with K-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initialize an empty list for Lasso RMSE scores\n",
    "lasso_rmse_scores = []\n",
    "\n",
    "# Specify the regularization strength for Lasso regression\n",
    "alpha_lasso = 1.0\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of Lasso regression\n",
    "    lasso_model = Lasso(alpha=alpha_lasso)\n",
    "    \n",
    "    # Fit the model\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = lasso_model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE and append to the list\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Lasso RMSE:\", rmse)\n",
    "    lasso_rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE\n",
    "average_lasso_rmse = np.mean(lasso_rmse_scores)\n",
    "print(\"Average Lasso RMSE:\", average_lasso_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desicion tree with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Initialize an empty list to store the RMSE for each fold\n",
    "dt_rmse_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of DecisionTreeRegressor\n",
    "    # Adjust max_depth, min_samples_split, and/or min_samples_leaf as needed\n",
    "    dt_model = DecisionTreeRegressor(max_depth=None) # Use default values or adjust as necessary\n",
    "    \n",
    "    # Fit the model\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = dt_model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE and append to the list\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Decision Tree RMSE:\", rmse)\n",
    "    dt_rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE\n",
    "average_dt_rmse = np.mean(dt_rmse_scores)\n",
    "print(\"Average Decision Tree RMSE:\", average_dt_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with k Fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Initialize an empty list to store the RMSE for each fold\n",
    "random_forest_rmse_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of the RandomForestRegressor\n",
    "    random_forest_model = RandomForestRegressor(n_estimators=100)  # You can adjust the number of trees\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    random_forest_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    y_pred = random_forest_model.predict(X_test)\n",
    "    \n",
    "    # Calculate the RMSE for the current fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Print the RMSE for the current fold\n",
    "    print(\"Random Forest RMSE:\", rmse)\n",
    "    \n",
    "    # Append the RMSE to the list of scores\n",
    "    random_forest_rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "average_random_forest_rmse = np.mean(random_forest_rmse_scores)\n",
    "\n",
    "# Print the average RMSE\n",
    "print(\"Average Random Forest RMSE:\", average_random_forest_rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
