{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import target.npy and train.npy\n",
    "# Train a model using train.npy\n",
    "# Test the model using target.npy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import the data\n",
    "train = np.load('dataset/train.npy')\n",
    "target = np.load('dataset/target.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.906324519062298\n",
      "RMSE: 1.811457932005012\n",
      "RMSE: 1.856984817994169\n",
      "RMSE: 1.8469065603446984\n",
      "RMSE: 1.8518672416355342\n",
      "Average RMSE: 1.8547082142083422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Initialize an empty list to store the root mean squared errors (RMSE) for each fold\n",
    "rmse_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of LinearRegression\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the RMSE for the current fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Print the RMSE for the current fold\n",
    "    print(\"RMSE:\", rmse)\n",
    "    \n",
    "    # Append the RMSE to the list of scores\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "average_rmse = np.mean(rmse_scores)\n",
    "\n",
    "# Print the average RMSE\n",
    "print(\"Average RMSE:\", average_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost with KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary modules\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_scores_xgboost = []\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of xgb.DMatrix for the training and testing sets\n",
    "    xgb_train = xgb.DMatrix(X_train, y_train)\n",
    "    xgb_test = xgb.DMatrix(X_test, y_test)\n",
    "\n",
    "    # Define the parameters for the XGBoost model\n",
    "    params = {\n",
    "        'colsample_bytree': 0.8,                 \n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.8,\n",
    "        'objective': 'reg:squarederror',\n",
    "    }\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model = xgb.train(params, xgb_train, num_boost_round=100)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(xgb_test)\n",
    "\n",
    "    # Calculate the RMSE for the current fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Print the RMSE for the current fold\n",
    "    print(\"RMSE:\", rmse)\n",
    "\n",
    "    # Append the RMSE to the list of scores\n",
    "    rmse_scores_xgboost.append(rmse)\n",
    "\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "average_rmse = np.mean(rmse_scores_xgboost)\n",
    "\n",
    "# Print the average RMSE\n",
    "print(\"Average RMSE:\", average_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM with KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_scores_lightgbm = []\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of lgb.Dataset for the training and testing sets\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_test = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "    # Define the parameters for the LightGBM model\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    model = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "\n",
    "    # Make predictions on the testing data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate the RMSE for the current fold\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Print the RMSE for the current fold\n",
    "    print(\"RMSE:\", rmse)\n",
    "\n",
    "    # Append the RMSE to the list of scores\n",
    "    rmse_scores_lightgbm.append(rmse)\n",
    "\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "average_rmse = np.mean(rmse_scores_lightgbm)\n",
    "\n",
    "# Print the average RMSE\n",
    "print(\"Average RMSE:\", average_rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge RMSE: 1.9063042351818682\n",
      "Ridge RMSE: 1.8112543823578533\n",
      "Ridge RMSE: 1.8569727958410416\n",
      "Ridge RMSE: 1.8469362815762222\n",
      "Ridge RMSE: 1.8518775569484203\n",
      "Average Ridge RMSE: 1.8546690503810812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Create an instance of KFold with the specified number of folds\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "# Initialize an empty list to store the RMSE for each fold\n",
    "ridge_rmse_scores = []\n",
    "\n",
    "# Specify the regularization strength for Ridge regression\n",
    "alpha_ridge = 1.0\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of Ridge regression\n",
    "    ridge_model = Ridge(alpha=alpha_ridge)\n",
    "    \n",
    "    # Fit the model\n",
    "    ridge_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = ridge_model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE and append to the list\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Ridge RMSE:\", rmse)\n",
    "    ridge_rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE\n",
    "average_ridge_rmse = np.mean(ridge_rmse_scores)\n",
    "print(\"Average Ridge RMSE:\", average_ridge_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso RMSE: 2.1332342216645404\n",
      "Lasso RMSE: 2.055400695762536\n",
      "Lasso RMSE: 2.0796900553177444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Initialize an empty list for Lasso RMSE scores\n",
    "lasso_rmse_scores = []\n",
    "\n",
    "# Specify the regularization strength for Lasso regression\n",
    "alpha_lasso = 1.0\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(train):\n",
    "    # Split the data\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    \n",
    "    # Create an instance of Lasso regression\n",
    "    lasso_model = Lasso(alpha=alpha_lasso)\n",
    "    \n",
    "    # Fit the model\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = lasso_model.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE and append to the list\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Lasso RMSE:\", rmse)\n",
    "    lasso_rmse_scores.append(rmse)\n",
    "\n",
    "# Calculate the average RMSE\n",
    "average_lasso_rmse = np.mean(lasso_rmse_scores)\n",
    "print(\"Average Lasso RMSE:\", average_lasso_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
