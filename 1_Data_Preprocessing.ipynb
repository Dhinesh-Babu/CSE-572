{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import category_encoders\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# from isotree import IsolationForest\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "DATA_PATH = \"dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing.\n",
    "<INSERT STEPS HERE>\n",
    "output: train.npy,test.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting isotree\n",
      "  Using cached isotree-0.6.1.post2.tar.gz (300 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: isotree\n",
      "  Building wheel for isotree (pyproject.toml): started\n",
      "  Building wheel for isotree (pyproject.toml): finished with status 'error'\n",
      "Failed to build isotree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for isotree (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [16 lines of output]\n",
      "      C:\\Users\\dublu\\AppData\\Local\\Temp\\pip-build-env-ph3eewo1\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\extension.py:134: UserWarning: Unknown Extension options: 'install_requires'\n",
      "        warnings.warn(msg)\n",
      "      C:\\Users\\dublu\\AppData\\Local\\Temp\\pip-build-env-ph3eewo1\\overlay\\Lib\\site-packages\\setuptools\\dist.py:318: InformationOnly: Normalizing '0.6.1-2' to '0.6.1.post2'\n",
      "        self.metadata.version = self._normalize_version(self.metadata.version)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-310\n",
      "      creating build\\lib.win-amd64-cpython-310\\isotree\n",
      "      copying isotree\\__init__.py -> build\\lib.win-amd64-cpython-310\\isotree\n",
      "      running build_ext\n",
      "      Compiling isotree/cpp_interface.pyx because it changed.\n",
      "      [1/1] Cythonizing isotree/cpp_interface.pyx\n",
      "      building 'isotree._cpp_interface' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for isotree\n",
      "ERROR: Could not build wheels for isotree, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\dublu\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "\n",
    "# Remove outliers\n",
    "train_df = train_df [ train_df['building_id'] != 1099 ]\n",
    "train_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')\n",
    "\n",
    "building_df = pd.read_csv(DATA_PATH + 'building_metadata.csv')\n",
    "weather_df = pd.read_csv(DATA_PATH + 'weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     building_id  meter            timestamp  meter_reading\n",
      "103          105      0  2016-01-01 00:00:00        23.3036\n",
      "104          106      0  2016-01-01 00:00:00         0.3746\n",
      "105          106      3  2016-01-01 00:00:00         0.0000\n",
      "106          107      0  2016-01-01 00:00:00       175.1840\n",
      "107          108      0  2016-01-01 00:00:00        91.2653\n",
      "   site_id  building_id primary_use  square_feet  year_built  floor_count\n",
      "0        0            0   Education         7432      2008.0          NaN\n",
      "1        0            1   Education         2720      2004.0          NaN\n",
      "2        0            2   Education         5376      1991.0          NaN\n",
      "3        0            3   Education        23685      2002.0          NaN\n",
      "4        0            4   Education       116607      1975.0          NaN\n",
      "   site_id            timestamp  air_temperature  cloud_coverage  \\\n",
      "0        0  2016-01-01 00:00:00             25.0             6.0   \n",
      "1        0  2016-01-01 01:00:00             24.4             NaN   \n",
      "2        0  2016-01-01 02:00:00             22.8             2.0   \n",
      "3        0  2016-01-01 03:00:00             21.1             2.0   \n",
      "4        0  2016-01-01 04:00:00             20.0             2.0   \n",
      "\n",
      "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  \\\n",
      "0             20.0                NaN              1019.7             0.0   \n",
      "1             21.1               -1.0              1020.2            70.0   \n",
      "2             21.1                0.0              1020.2             0.0   \n",
      "3             20.6                0.0              1020.1             0.0   \n",
      "4             20.0               -1.0              1020.0           250.0   \n",
      "\n",
      "   wind_speed  \n",
      "0         0.0  \n",
      "1         1.5  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         2.6  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(building_df.head())\n",
    "print(weather_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/aitude/ashrae-missing-weather-data-handling by @aitude\n",
    "\n",
    "def fill_weather_dataset(weather_df):\n",
    "    \n",
    "    # Find Missing Dates\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n",
    "    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n",
    "    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n",
    "    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n",
    "\n",
    "    missing_hours = []\n",
    "    for site_id in range(16):\n",
    "        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n",
    "        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n",
    "        new_rows['site_id'] = site_id\n",
    "        weather_df = pd.concat([weather_df,new_rows])\n",
    "\n",
    "        weather_df = weather_df.reset_index(drop=True)           \n",
    "\n",
    "    # Add new Features\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    weather_df[\"day\"] = weather_df[\"datetime\"].dt.day\n",
    "    weather_df[\"week\"] = weather_df[\"datetime\"].dt.weekday\n",
    "    weather_df[\"month\"] = weather_df[\"datetime\"].dt.month\n",
    "    \n",
    "    # Reset Index for Fast Update\n",
    "    weather_df = weather_df.set_index(['site_id','day','month'])\n",
    "\n",
    "    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n",
    "    weather_df.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "    # Step 2\n",
    "    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
    "\n",
    "    weather_df.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n",
    "    weather_df.update(due_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "    # Step 2\n",
    "    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "\n",
    "    weather_df.update(sea_level_filler,overwrite=False)\n",
    "\n",
    "    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n",
    "    weather_df.update(wind_direction_filler,overwrite=False)\n",
    "\n",
    "    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n",
    "    weather_df.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "    # Step 2\n",
    "    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "\n",
    "    weather_df.update(precip_depth_filler,overwrite=False)\n",
    "\n",
    "    weather_df = weather_df.reset_index()\n",
    "    weather_df = weather_df.drop(['datetime','day','week','month'],axis=1)\n",
    "        \n",
    "    return weather_df\n",
    "\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def features_engineering(df):\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df.sort_values(\"timestamp\")\n",
    "    df.reset_index(drop=True)\n",
    "    \n",
    "    # Add more features\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n",
    "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
    "                    \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
    "                    \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
    "                    \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
    "                    \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
    "                    \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
    "                    \"2019-01-01\"]\n",
    "    df[\"is_holiday\"] = (df.timestamp.isin(holidays)).astype(int)\n",
    "    df['square_feet'] =  np.log1p(df['square_feet']**0.5)\n",
    "    \n",
    "    # Remove Unused Columns\n",
    "    drop = [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"]\n",
    "    df = df.drop(drop, axis=1)\n",
    "    gc.collect()\n",
    "    \n",
    "    # Encode Categorical Data\n",
    "    le = LabelEncoder()\n",
    "    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:36: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:59: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n"
     ]
    }
   ],
   "source": [
    "weather_df = fill_weather_dataset(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 757.31 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 322.18 MB\n",
      "Decreased by 57.5%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.9%\n",
      "Memory usage of dataframe is 9.65 MB\n",
      "Memory usage after optimization is: 2.60 MB\n",
      "Decreased by 73.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
      "C:\\Users\\dublu\\AppData\\Local\\Temp\\ipykernel_37172\\2128334198.py:82: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n"
     ]
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df,use_float16=True)\n",
    "building_df = reduce_mem_usage(building_df,use_float16=True)\n",
    "weather_df = reduce_mem_usage(weather_df,use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.merge(building_df, left_on='building_id',right_on='building_id',how='left')\n",
    "train_df = train_df.merge(weather_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])\n",
    "del weather_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = features_engineering(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.420515</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.308213</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.308213</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.747165</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.658165</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter  site_id  primary_use  square_feet  air_temperature  \\\n",
       "0          105      0        1            0     5.420515         3.800781   \n",
       "1          106      0        1            0     4.308213         3.800781   \n",
       "2          106      3        1            0     4.308213         3.800781   \n",
       "3          107      0        1            0     5.747165         3.800781   \n",
       "4          108      0        1            0     5.658165         3.800781   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  \n",
       "0             0.0         2.400391                0.0  \n",
       "1             0.0         2.400391                0.0  \n",
       "2             0.0         2.400391                0.0  \n",
       "3             0.0         2.400391                0.0  \n",
       "4             0.0         2.400391                0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.log1p(train_df[\"meter_reading\"])\n",
    "train = train_df.drop(['meter_reading', 'is_holiday', 'hour', 'weekend'], axis = 1)\n",
    "del train_df\n",
    "gc.collect()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", \"primary_use\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8784</td>\n",
       "      <td>11706016</td>\n",
       "      <td>553357</td>\n",
       "      <td>8050507</td>\n",
       "      <td>5.420515</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17564</td>\n",
       "      <td>11706016</td>\n",
       "      <td>553357</td>\n",
       "      <td>8050507</td>\n",
       "      <td>4.308213</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17564</td>\n",
       "      <td>1264037</td>\n",
       "      <td>553357</td>\n",
       "      <td>8050507</td>\n",
       "      <td>4.308213</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8784</td>\n",
       "      <td>11706016</td>\n",
       "      <td>553357</td>\n",
       "      <td>8050507</td>\n",
       "      <td>5.747165</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8784</td>\n",
       "      <td>11706016</td>\n",
       "      <td>553357</td>\n",
       "      <td>8050507</td>\n",
       "      <td>5.658165</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id     meter  site_id  primary_use  square_feet  air_temperature  \\\n",
       "0         8784  11706016   553357      8050507     5.420515         3.800781   \n",
       "1        17564  11706016   553357      8050507     4.308213         3.800781   \n",
       "2        17564   1264037   553357      8050507     4.308213         3.800781   \n",
       "3         8784  11706016   553357      8050507     5.747165         3.800781   \n",
       "4         8784  11706016   553357      8050507     5.658165         3.800781   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  \n",
       "0             0.0         2.400391                0.0  \n",
       "1             0.0         2.400391                0.0  \n",
       "2             0.0         2.400391                0.0  \n",
       "3             0.0         2.400391                0.0  \n",
       "4             0.0         2.400391                0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = category_encoders.CountEncoder(cols=categorical_features)\n",
    "ce.fit(train)\n",
    "train = ce.transform(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>5.420515</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>4.308213</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.063672</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>4.308213</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>5.747165</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.027874</td>\n",
       "      <td>0.405518</td>\n",
       "      <td>5.658165</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id     meter   site_id  primary_use  square_feet  air_temperature  \\\n",
       "0     0.000442  0.589652  0.027874     0.405518     5.420515         3.800781   \n",
       "1     0.000885  0.589652  0.027874     0.405518     4.308213         3.800781   \n",
       "2     0.000885  0.063672  0.027874     0.405518     4.308213         3.800781   \n",
       "3     0.000442  0.589652  0.027874     0.405518     5.747165         3.800781   \n",
       "4     0.000442  0.589652  0.027874     0.405518     5.658165         3.800781   \n",
       "\n",
       "   cloud_coverage  dew_temperature  precip_depth_1_hr  \n",
       "0             0.0         2.400391                0.0  \n",
       "1             0.0         2.400391                0.0  \n",
       "2             0.0         2.400391                0.0  \n",
       "3             0.0         2.400391                0.0  \n",
       "4             0.0         2.400391                0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_train = train.shape[0]\n",
    "for feature in categorical_features:\n",
    "    train[feature] = train[feature]/N_train\n",
    "    \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\niso = IsolationForest(build_imputer=True, prob_pick_pooled_gain=1, ntry=10)\\niso.fit(train)\\ntrain = iso.transform(train)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "iso = IsolationForest(build_imputer=True, prob_pick_pooled_gain=1, ntry=10)\n",
    "iso.fit(train)\n",
    "train = iso.transform(train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(train)\n",
    "train = imp.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# store train data and target for easier use\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/train.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, train)\n\u001b[0;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/target.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, target)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# store train data and target for easier use\n",
    "np.save('dataset/train.npy', train)\n",
    "np.save('dataset/target.npy', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, target\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
